{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summaries and Tensorboard\n",
    "In this notebook we extend the previous example by adding summaries to the computation graph, \n",
    "and writing these summaries to a logfile in the training loop. These logfiles can than be looked at in tensorboard, a utility program that comes with tensorflow. It is tremendously helpful when debugging a model, or even for simply monitoring its progress.\n",
    "\n",
    "To get a more interesting learning graph the number of training steps has been increased.\n",
    "\n",
    "Summary operations take a tensor value and serialize it to a string that can be used for logging/monitoring. \n",
    "Summary operations are part of `tf.summary` and include\n",
    "* `tf.summary.scalar`\n",
    "* `tf.summary.image`\n",
    "* `tf.summary.audio`\n",
    "* `tf.summary.histogram`\n",
    "* `tf.summary.text`\n",
    "\n",
    "Multiple summaries an be joined using `tf.summary.merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import numpy as np\n",
    "\n",
    "NUM_STEPS = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the Network\n",
    "This code is mostly as before, but with a few summary operations sprinkled in. \n",
    "We generate a histogram of the logit and probability values. \n",
    "\n",
    "One thing that is always recommended to do is to monitor your input data in the network. \n",
    "This is to make sure that the data after preprocessing is actually something the network can work with.\n",
    "(e.g. the image format is as expected, cropping and resizing do not destroy the information we want to learn from etc.)\n",
    "\n",
    "To visualize the image we need to convert the column vector into an image shaped tensor. The last dimension gets a size of 1, indicating a grayscale image. The batch dimension gets a size of -1 to indicate that the value is to be chosen such that the total number of elements matches up. (We cannot pass `None` here, since the new shape is a Tensor, and as such each entry needs to be of type int). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 784), name=\"x\")\n",
    "tf.summary.image(\"image\", tf.reshape(x, (-1, 28, 28, 1)))\n",
    "\n",
    "y = tf.placeholder(tf.int32, (None), name=\"y\")\n",
    "\n",
    "W = tf.Variable(np.random.random((784, 10)), dtype=tf.float32, name=\"W\")\n",
    "b = tf.Variable(np.random.random(10), dtype=tf.float32, name=\"b\")\n",
    "\n",
    "l = tf.matmul(x, W) + b\n",
    "tf.summary.histogram(\"logits\", l)\n",
    "\n",
    "p = tf.nn.softmax(l)\n",
    "tf.summary.histogram(\"probabilities\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loss and Optimizer\n",
    "This is almost the same as before. We moved the loss calculation into a `name_scope` to get the graph a bit more structured, and added a summary for the `loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss_calculation\"):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(y, depth=10), logits=l)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We now calculate the accuracy of our predictions. \n",
    "We put all operations into a name scope to get a more readable graph. The `name_scope` function takes an optional second argument which is a list of tensors we want to use within this scope. This checks that all Tensors are defined in the same graph, but can usually be omitted when writing a model (everything is in the default graph anyway).\n",
    "\n",
    "The calculation of the accuracy is done like this: First we calculate the prediced class (as an integer), and compare that to the given labels. This results in a boolean tensor, so before we calculate the mean we cast it to a floating point type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy_calc\", [l, y]):\n",
    "    predicted = tf.argmax(l, axis=1, name=\"predicted\")\n",
    "    correct = tf.equal(tf.cast(predicted, tf.int32), y, name=\"is_correct\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading Data and Initialization\n",
    "This remains unchanged from the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the dataset and create a session\n",
    "mnist = tflearn.datasets.load_dataset(\"mnist\")\n",
    "images = mnist.train.images\n",
    "labels = mnist.train.labels\n",
    "\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "# Important: Initialize the Variables.\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary Writer\n",
    "Here we create the summary writer, that writes all summaries into the `tensorboard_demo` directory. It immediately write a description of the computation graph associated with `session`, which is just the default graph in which we built our model. We also create a *merged* summary operation that combiens all the summaries defined above.\n",
    "\n",
    "Please note that by using a fixed path name, executing this notebook for the second time will write another log file into the same directory, which will lead to artifacts in tensorboard visualizations. If you execpt to train the model multiple times, either delete the summary directory before restarting, or write into subdirectory for different runs. The last option is also necessary if you want to compare different runs in tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "summaries = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"tensorboard_demo\", session.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training Loop\n",
    "Instead of the loss scalar, we now extract the merge summary. The result is added to the `writer`. The `add_summary` function also expects a time step, so we put in the loop counter. This is used for the x axis in the tensorboard plots. Finally, we close the `writer` again. This ensures that all summaries that have not yet been written to file will be written now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(NUM_STEPS):\n",
    "    summary, _ = session.run([summaries, train_op], {x: images, y: labels})\n",
    "    writer.add_summary(summary, i)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tensorboard\n",
    "To view the logs in tensorboard you can simply start the tensorboard server using\n",
    "```bash\n",
    ">> tensorboard --logdir tensorboard_demo\n",
    "```\n",
    "and then visit `127.0.0.1:6006` with your webbrowser. If that port is in use for some reason, you can specify the `--port` option when starting tensorboard. (On some machines `127.0.0.1` does not seem to work, you can try `localhost` instead). \n",
    "\n",
    "If you run your tensorflow code on another machine (e.g. on the cluster) and want to folow along with tensorboard, there are three options:\n",
    "- You may be able to simply access the tensorboard address on the remote system by going to `[REMOTE_ADDRESS]:6006`.\n",
    "- Set the logdir to a network mounted filesystem and run tensorboard locally, pointing to the network files.\n",
    "- Use an ssh redirection to mirror the address to your local system \n",
    "```bash\n",
    ">>> ssh -L 6006:127.0.0.1:6006 [USER]@[REMOTE_ADDRESS]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
