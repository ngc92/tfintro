{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Higher Level Interface\n",
    "\n",
    "Using the functions provided by tf.layers, we can easily build many standard network models. In this notebook it will be a Convolutional Network. \n",
    "\n",
    "The notebook also demonstrates different model modes: For training we built a slightly different version of the model than for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "NUM_EPISODES = 10\n",
    "RESTORE = False\n",
    "\n",
    "Model = namedtuple(\"Model\", [\"logits\", \"probabilities\", \"loss\", \"train_step\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(logits, labels, name=\"accuracy\"):\n",
    "    with tf.name_scope(name, [logits, labels]):\n",
    "        predicted = tf.argmax(logits, axis=1, name=\"predicted\")\n",
    "        correct = tf.equal(tf.cast(predicted, tf.int32), labels, name=\"is_correct\")\n",
    "        return tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### cnn forward pass\n",
    "A function that takes in some input features, and applies a cascade of cnns, followed by a dense multiplication. Depending on the application it might make sense to expose more configuration parameters to the outside (e.g. the kernel size, or the used nonlinearity).\n",
    "\n",
    "An additional parameter `is_training` is passed to indicate whether the forward model should be build in training or in evaluation mode. This influences the behaviour of the `dropout` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cnn_fn(x, channels=(32, 64), outputs=10, is_training=True):\n",
    "    hidden = x\n",
    "    for c in channels:\n",
    "        hidden = tf.layers.conv2d(hidden, c, kernel_size=3, strides=2,\n",
    "                                    activation=tf.nn.relu)\n",
    "    hidden = tf.layers.flatten(hidden)\n",
    "    hidden = tf.layers.dropout(hidden, 0.5, training=is_training)\n",
    "    return tf.layers.dense(hidden, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### model_fn\n",
    "Since we are using the higher level layers interface there is no more explicit access to any variable. Since a convolutional layer expects the input data to be shaped like an image we first perform a reshape on the data. If we built the network in evaluation mode we simple set the `train_op` to `None`. \n",
    "For evaluation we have also added the accuracy tensor as part of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_fn(x, y, is_training):\n",
    "    image_shaped = tf.reshape(x, (-1, 28, 28, 1))\n",
    "    tf.summary.image(\"image\", image_shaped)\n",
    "    l = cnn_fn(image_shaped, is_training=is_training)\n",
    "    tf.summary.histogram(\"logits\", l)\n",
    "    p = tf.nn.softmax(l)\n",
    "    tf.summary.histogram(\"probabilities\", p)\n",
    "    \n",
    "    with tf.name_scope(\"loss_calculation\"):\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(y, depth=10), logits=l)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    accuracy = calc_accuracy(l, y)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    global_step = tf.train.create_global_step()\n",
    "    if is_training:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    else:\n",
    "        train_op = None\n",
    "    return Model(logits=l, probabilities=p, loss=loss, train_step=train_op, accuracy=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "We build the graph for training mode. Since everything model specific happens in `model_fn` this code remains unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(tf.float32, (None, 784), name=\"x\")\n",
    "    y = tf.placeholder(tf.int32, (None), name=\"y\")\n",
    "    _, _, loss, train_op, _ = model_fn(x, y, is_training=True)\n",
    "    summaries = tf.summary.merge_all()\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "# load the dataset\n",
    "mnist = tflearn.datasets.load_dataset(\"mnist\")\n",
    "images = mnist.train.images\n",
    "labels = mnist.train.labels\n",
    "\n",
    "writer = tf.summary.FileWriter(\"high_level_demo\", graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training Loop\n",
    "We have put the training loop inside a `tf.Session` with-block. This ensures that the session will be closed after this cell is executed. Since we no longer build the model in the global default graph, we need to explicitly pass the graph object to the newly created session. \n",
    "\n",
    "Since the model is much bigger than before it needs much more memory, and as such cannot process the complete dataset in one batch on older GPUs. Therefore a little rudimentary minibatching was added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    if RESTORE:\n",
    "        saver.restore(session, tf.train.latest_checkpoint(\"high_level_demo\"))\n",
    "    else:\n",
    "        init.run()\n",
    "    \n",
    "    for i in range(NUM_EPISODES):\n",
    "        for j in range(int(len(images) / 100)):\n",
    "            imgs = images[100*j:100*j+100]\n",
    "            lbls = labels[100*j:100*j+100]\n",
    "            summary, _, step = session.run([summaries, train_op, tf.train.get_global_step()], {x: imgs, y: lbls})\n",
    "        writer.add_summary(summary, step)\n",
    "\n",
    "    saver.save(session, \"high_level_demo/model\", tf.train.global_step(session, tf.train.get_global_step()))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation\n",
    "For evaluation we built the complete graph with training disabled. Since we really want to process everything in one big batch for evaluation, we put the complete model on the CPU. (See how using a model_fn makes this a trivial task!). \n",
    "\n",
    "Then we construct a new session, restore the model we trained above, and run the loss and accuracy tensors. We calculate them for both the training set and the test set. In this way we can identify whether we overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device(\"/cpu:0\"):\n",
    "    x = tf.placeholder(tf.float32, (None, 784), name=\"x\")\n",
    "    y = tf.placeholder(tf.int32, (None), name=\"y\")\n",
    "    _, _, loss, _, accuracy = model_fn(x, y, is_training=False)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session, tf.train.latest_checkpoint(\"high_level_demo\"))\n",
    "    \n",
    "    loss_v, accuracy_v = session.run([loss, accuracy], {x: images, y: labels})\n",
    "    print(\"trainsing set: total loss: %s, accuracy: %s\" % (loss_v, accuracy_v))\n",
    "    \n",
    "    loss_v, accuracy_v = session.run([loss, accuracy], {x: mnist.test.images, y: mnist.test.labels})\n",
    "    print(\"test set: total loss: %s, accuracy: %s\" % (loss_v, accuracy_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Closing Remarks\n",
    "To see the difference between training and evaluation mode graph you can change the evaluation code to also use training mode. You should see a slight drop in accuracy (~1%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
